{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9536d9ad-250a-4323-9c4b-90c1137c59b3",
   "metadata": {},
   "source": [
    "##### HW 4, Part 2, Start\n",
    "### CSCI 4270 and 6270, Spring 2025\n",
    "\n",
    "This is starter code for HW 4, Part 2. Most important is the definition of the Dataset object for loading, separately, the train, validation and test image sets. Students can use as much or as little of this as they wish and can modify it in anyway they'd like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bece3632-019b-4ac0-be8c-39e882243355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c77e33-318a-4997-a3ae-9ed9dbbe98c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image(fn):\n",
    "    extensions = ['.jpg', '.jpeg', '.png']\n",
    "    return any(fn.lower().endswith(ext) for ext in extensions)\n",
    "\n",
    "def find_images_in_folder(folder_path, verbose=False):\n",
    "    full_image_paths = []\n",
    "    # Iterate through all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        # Check if the file is an image\n",
    "        if os.path.isfile(file_path) and is_image(filename):\n",
    "            # Try opening the image\n",
    "            try:\n",
    "                im = Image.open(file_path)\n",
    "                full_image_paths.append(file_path)\n",
    "                if verbose:\n",
    "                    print(f\"Read image: {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error failed to read {filename}: {e}\")\n",
    "    print(f'Returing {len(full_image_paths)} image paths')\n",
    "    return full_image_paths\n",
    "\n",
    "folder_path = \"hw4_data/valid/ocean\"\n",
    "full_paths = find_images_in_folder(folder_path, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213dff20-1862-4140-b684-893fe5b2e918",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Provide a Dataset object for the five class dataset.\n",
    "'''\n",
    "\n",
    "# These are empirically determined values to optimize image intensity rescaling prior to training\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "'''\n",
    "The Dataset class we write must include the __init__, __len__ and __getitem__ (subscripting) \n",
    "methods.\n",
    "'''\n",
    "class HW4_Dataset(Dataset):\n",
    "    def __init__(self, path, class_names, new_size=None, verbose=False):\n",
    "        '''\n",
    "        Produce a list of the full image paths and class indices for all images\n",
    "        in the given set (found along the path).  Record a transform to be\n",
    "        applied by the __getitem__ method to each image.\n",
    "        '''\n",
    "        self.full_image_paths = []\n",
    "        self.class_names = class_names\n",
    "        self.gt_class_idx = []\n",
    "        for idx, nm in enumerate(class_names):\n",
    "            folder_path = os.path.join(path, nm)\n",
    "            image_paths = find_images_in_folder(folder_path, verbose)\n",
    "            self.full_image_paths += image_paths\n",
    "            self.gt_class_idx += [idx] * len(image_paths)\n",
    "\n",
    "        if new_size is not None:\n",
    "            self.transform = transforms.Compose([transforms.Resize(new_size),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=MEAN, std=STD)])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=MEAN, std=STD)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.full_image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fp = self.full_image_paths[idx]\n",
    "        class_i = self.gt_class_idx[idx]\n",
    "        im = Image.open(fp)\n",
    "        im = self.transform(im)\n",
    "        return im, class_i\n",
    "        \n",
    "        \n",
    "class_names = ['grass', 'ocean', 'redcarpet', 'road', 'wheatfield']\n",
    "\n",
    "# new_size = 60   # This reduces the original 240x360 images to 60x90.  Setting it to 240 leaves the images unchanged\n",
    "new_size = None # Setting new_size to None keeps the original image size.\n",
    "verbose = False\n",
    "\n",
    "# Form all three datasets.\n",
    "train_dataset = HW4_Dataset(\"hw4_data/train\", class_names, new_size=new_size, verbose=verbose)\n",
    "valid_dataset = HW4_Dataset(\"hw4_data/valid\", class_names, new_size=new_size, verbose=verbose)\n",
    "test_dataset = HW4_Dataset(\"hw4_data/test\", class_names, new_size=new_size, verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47d323f-1e8d-48a1-a3a0-d1152f1b1a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Explore the constructed dataset\n",
    "'''\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Find and output the number of images\n",
    "n = len(valid_dataset)\n",
    "print(f'The validation dataset has {n} images')\n",
    "\n",
    "# Randomly shuffle the image indices\n",
    "indices = list(range(n))\n",
    "random.shuffle(indices)\n",
    "\n",
    "# Get the image and the class id of the 0th image after the shuffle.\n",
    "im, class_idx = valid_dataset[indices[0]]\n",
    "print(f'After the shuffle the 0th image has class index {class_idx}')\n",
    "\n",
    "# Convert the image from an array back to a numpy 3d array\n",
    "im_np = im.numpy().transpose((1, 2, 0))\n",
    "print(f'Image shape is {im_np.shape}')\n",
    "\n",
    "# Before displaying the image rescale the intensities to be between 0 and 1\n",
    "im_min = im_np.min()\n",
    "im_max = im_np.max()\n",
    "im_np = (im_np - im_min) / (im_max - im_min)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(im_np)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(class_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
